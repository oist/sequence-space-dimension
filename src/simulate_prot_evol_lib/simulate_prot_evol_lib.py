#!/usr/bin/env python3
# -*- coding: utf-8 -*-

# This is the library for simulating protein families 
#
# Function sections:
# 1. Sequence and allowed substitution matrix generation
# 2. Protein family evolution simulation
#   2.1 No epistasis
#   2.2 With epistasis
# 3. Generate and evolve tree
# 4. Get stats

# How to use this library:
# import sys
# add the path to the simulate_prot_evol.py and  __init__.py files to your path 
#sys.path.append("/bucket/KondrashovU/seq_space/scripts/seq_space_lib/")
#sys.path.append("../scripts/seq_space_lib/")
#import sequence_space_lib as seqsp
#
#sys.path.append("/bucket/KondrashovU/seq_space/scripts/simulate_prot_evol_lib/")
#sys.path.append("../scripts/simulate_prot_evol_lib/")
#import simulate_prot_evol_lib as simevol

import random
import scipy
import textwrap
import itertools
import copy
from tqdm import tqdm
import os
import re
import numpy as np
import pandas as pd
from Bio.Data import CodonTable
from Bio.Seq import Seq
from Bio.SeqRecord import SeqRecord
from Bio import AlignIO
from Bio.Align import MultipleSeqAlignment
import dnds
import sys
import pickle
from scipy.spatial.distance import pdist, squareform
sys.path.append("../seq_space_lib/")
import sequence_space_lib as seqsp
from ete3 import Tree


# --- 1. Sequence and allowed substitution matrix generation

def generate_nt_seq(seq_len, number_of_sequences, seqfrom='matrix', matrix=None, select_from='aa'):
    
    """Function that generates random nucleotide coding sequence(s).

    Args:
        seq_len (int): length of sequence to generate in nucleotides 
        number_of_sequences (int): number of sequences to generate
        seqfrom (str): 'matrix' or 'random' - mode of operation:
            - 'matrix' - Uses only allowed codons from the substitution matrix in sequence generation
            - 'random' - Randomly chooses the sequence of codons (excluding stop codons)
        matrix (dict or np.array): substitution matrix (needed only if seqfrom == 'matrix'), 
            if np.array, the shape should be 20 x SEQ_LEN.
        select_from (str): 'aa' or 'codon' - mode of operation:
            - 'aa' -  the probabilities of the allowed amino acids 
               are all equal
            - 'codon' - the probabilities of codons are equal but the probabilities of different amino 
            acids are proportional to the number of codons they have

    Returns:
        sequences (list/str): list of sequences generated by the function/sequence
    
    IMPORTANT: by default if seqfrom='matrix' the probabilities of the allowed amino acids 
               are all equal whithin one position in the matrix. The amio acid is selected first,
               and the codon for it is selected after from the list of possible codons for this
               amino acid.
               if seqfrom='random', the sequence used to be composed of codons - therefore the probabilities
               of different amino acids are proportional to the number of codons they have. 
               Now aa is the default. 

    """
    standard_table = CodonTable.unambiguous_dna_by_name["Standard"]
    codons = list(standard_table.forward_table.keys())

    if seq_len %3!=0 and matrix==None:
        raise ValueError('Sequence length is not propely set') 

    sequences = []

    gencodedf=pd.DataFrame({'codon':list(standard_table.forward_table.keys())})
    gencodedf.index = list(standard_table.forward_table.values())

    if seqfrom == 'matrix':
        # allow for np.array input matrix format 
        if type(matrix)==dict:
            all_aa=list(matrix.keys())
            matr_arr=np.array(list(matrix.values())).T
        else:
            all_aa=['E', 'Q', 'R', 'F', 'N', 'A', 'V', 'D', 'Y', 'S', 'I', 'M', 'G', 'W', 'H', 'K', 'P', 'C', 'T', 'L']
            matr_arr=matrix.T

        if select_from=='aa':
            for _ in range(number_of_sequences):
                sequence = []
                for i in matr_arr:
                    prot = random.choices(all_aa, weights=i, k=1)[0]
                    if prot == "W":
                        sequence.append('TGG')
                    elif prot == "M":
                        sequence.append('ATG')
                    else:
                        sequence.append(random.choice(list(gencodedf['codon'][prot])))
                sequence = "".join(sequence)
                sequences.append(sequence)

        elif select_from=='codon':
            for _ in range(number_of_sequences):
                sequence = []
                for i in matr_arr:
                    allowed_aa=np.array(all_aa)[np.array(i, dtype=bool)]
                    sequence.append(random.choice(list(gencodedf.loc[allowed_aa]['codon'])))
                sequence = "".join(sequence)
                sequences.append(sequence)

    elif seqfrom == 'random':
        if select_from=='aa':
            all_aa=['E', 'Q', 'R', 'F', 'N', 'A', 'V', 'D', 'Y', 'S', 'I', 'M', 'G', 'W', 'H', 'K', 'P', 'C', 'T', 'L']
            for _ in range(number_of_sequences):
                sequence = []
                for i in range(seq_len//3):
                    prot = random.choices(all_aa, k=1)[0]
                    if prot == "W":
                        sequence.append('TGG')
                    elif prot == "M":
                        sequence.append('ATG')
                    else:
                        sequence.append(random.choice(list(gencodedf['codon'][prot])))
                sequence = "".join(sequence)
                sequences.append(sequence)

        elif select_from=='codon':
            for _ in range(number_of_sequences):
                seq_str = ''.join(random.choices(codons,k=seq_len//3))
                sequences.append(seq_str)

    if number_of_sequences == 1:
        sequences = sequences[0]  
        
    return sequences


def generate_matrix_AA(prot_len, fraction=0.5):

    """_summary_
    it generates random substitution matrix

    Args:
        prot_len (int): length of protein sequence
        fraction (float): fraction of substitutions

    Returns:
        substitution_matrix (dict): dict of substitution matrix
    
    """
    if fraction > 1 or fraction < 0.05:
        raise ValueError('Fraction is lower than 5% (1 aa per site) for more than 100%')
    
    elif fraction >= 0.3: #use this way of generating the matrix (very fast)

        matrix = np.random.choice([1,0], size=(prot_len, 20), p = [fraction, 1 - fraction])
        #make sure that every site has at least one allowed amino acid (if not - generate a new one)
        while np.any(np.sum(matrix, axis=1) <= 0):
            matrix = np.random.choice([1,0], size=(prot_len, 20), p = [fraction, 1 - fraction])
    
    else: #use this way of generating the matrix for low fraction of allowed aa

        # Step 1: Create an empty matrix of zeros
        matrix = np.zeros((prot_len, 20), dtype=int)

        # Step 2: Calculate the total number of 1's needed based on the fraction
        total_elements = prot_len * 20
        total_ones = int(round(total_elements * fraction, 0))

        # Step 3: Place at least one 1 in each row
        # Random column index in the row
        ones_indices=np.random.randint(20, size=prot_len)
        for i, j in enumerate(ones_indices):
            matrix[i, j] = 1
        # Reduce the remaining ones count
        total_ones=total_ones-prot_len

        # Step 4: Place the remaining 1's randomly in the matrix
        if total_ones > 0:
            indices = np.argwhere(matrix == 0)  # Get all indices of 0's
            chosen_indices = indices[np.random.choice(len(indices), total_ones, replace=False)]
            matrix[chosen_indices[:, 0], chosen_indices[:, 1]] = 1

    standard_table = CodonTable.unambiguous_dna_by_name["Standard"]
    amino_acids = set(standard_table.forward_table.values())
    substitution_matrix = {}
    # Populate the substitution matrix
    for i, aa in enumerate(amino_acids):
        substitution_matrix[aa] = matrix[:,i]

    return substitution_matrix

# --- 2. Mutate/evolve seqeunces

# --- 2.1 No epistasis

def mutate_seq(sequence, matrix, limit = 5, limit_on='all_subs'):
    
    """
    Function that evolves (mutates) coding sequence(s).
    Only substitutions specified in the MATRIX are allowed to fix. 
    Args:
        sequence (str): nucleotide sequence to  evolve
        matrix (dict): dictionary of allowed substitutions
                        keys - amino acids
                        values - np.arrays with N elements each, where N is number of sites
                        in the translated sequence, with elements in [0,1], where 1 signifies 
                        that given amino acid (key) is allowed at this site (index in the array), 
                        0 - not allowed
        limit (int): number of substitutions/substitution attemts to happen before the function stops.
        limit_on (str) ['all_subs', 'all_attempts', 'syn_subs'] : which substitutions events or 
                        attemts to use to stop the evolution

        NOTE ON LIMIT_ON=SYN_SUBS: there are ususally 0.25*seq_len synonymous sites (so dS=0.5 will
        correspond to 0.125*seq_len synonymous substitutions) 

    Returns:
        dictionary with the following elements:
            - sequence (str): evolved sequence
            - syn_count (int): number of synonymous substitutions
            - count_all (int): number of all mutation attmpts (including non-allowed)
            - count_good (int): number of allowed substitution events
    
    """

    count_good = 0
    
    #initialize gen code 
    standard_table = CodonTable.unambiguous_dna_by_name["Standard"]

    #get index of the last position in the nucleotide sequence
    seq_last_pos_ind=len(sequence)-1

    #split mutated sequence into codons
    seq_in_codons=textwrap.wrap(sequence, 3)

    #set how to track time
    limit_var={'all_subs':0, 'all_attempts':0, 'syn_subs':0}

    while (limit_var[limit_on] < limit):

        #create list of nucleotides
        nucl = ["A","C","G","T"]

        #generate random mutation position
        mutation_pos = random.randint(0,seq_last_pos_ind)

        #get mutated codon and nucleotide
        mut_codon_pos=mutation_pos//3
        mut_pos_in_codon=mutation_pos%3

        #get original codon 
        oldcodon = seq_in_codons[mut_codon_pos]
        current_nuc_in_pos = oldcodon[mut_pos_in_codon]

        # remove current nuc from list of possible mutations
        nucl.remove(current_nuc_in_pos)

        #pick mutation
        mutation_nuc = random.choice(nucl)
        newcodon=oldcodon[:mut_pos_in_codon] + mutation_nuc + oldcodon[mut_pos_in_codon + 1:]

        #count mutation event
        limit_var['all_attempts'] += 1

        if newcodon in standard_table.stop_codons: #don't fix mutation if it is a nonsense mutation
            #print('nonsense_mut')
            continue
        else: 
            #get amino acid toward which the mutation has happened
            newmutation_aa=standard_table.forward_table[newcodon]
            #check if it's a missence mutation (change in aa)
            if newmutation_aa==standard_table.forward_table[oldcodon]:
                #print(newcodon, newmutation_aa, oldcodon, standard_table.forward_table[oldcodon])
                #synonymous mutation
                limit_var['syn_subs'] += 1
                #keep mutation 
                seq_in_codons[mut_codon_pos]=newcodon
                #print('syn_mut')
            else: #non-synonymous mutation
                if matrix[newmutation_aa][mut_codon_pos]==1:
                    # allowed sequence (Non-synonymous GOOD mutation)
                    count_good +=1
                    seq_in_codons[mut_codon_pos]=newcodon
                    # print('Non-synonymous GOOD mutation') 
                    #print('good_mut')
                else:
                    #print('bad_mut')
                    continue
        #update the count of all substitutions that happened        
        limit_var['all_subs'] = count_good + limit_var['syn_subs'] 
        #print(limit_var)

    return {'sequence':"".join(seq_in_codons),
            'count_syn':limit_var['syn_subs'],
            'count_good':count_good,
            'count_all':limit_var['all_attempts']}


def evolve_seq_w_matrix(seq_len, frac_range, sub_matrixes: list, limit=110, limit_on='syn_subs',
                                  num_of_seq=50, startingseq='same', seqfrom='matrix', diffmatrix=False,
                                  normal_limit=False, limit_sigma=0.1):
    
    """Function to simulate the evolved sequences for 1 protein family 
    (if startingseq='same')
    
    Outputs (for each F): 
    - list of evolved sequences
    - list of ancestor sequences
    """    
    alis_by_f=[]
    ancestors_by_f=[]

    for ind, F in tqdm(enumerate(frac_range)):

        #set substitution matrix
        sub_matrix = sub_matrixes[ind]

        #set the starting sequence
        if startingseq == 'same':
            random_sequence = [generate_nt_seq(seq_len, 1, seqfrom=seqfrom, matrix=sub_matrix)]*num_of_seq
        elif startingseq == 'different':
            random_sequence = generate_nt_seq(seq_len, num_of_seq, seqfrom=seqfrom, matrix=sub_matrix)

        #set the divergence limit
        if normal_limit:
            limits=np.random.normal(limit, limit*limit_sigma, size=num_of_seq)
        else:
            limits=[limit]*num_of_seq

        #set output array 
        evolved_sequence=[]

        #start evolution
        if diffmatrix==False:
            for replicate, replimit in enumerate(limits):
                evol = mutate_seq(random_sequence[replicate], limit=replimit, limit_on=limit_on, matrix=sub_matrix)
                evolved_sequence.append(evol['sequence'])
                
        elif diffmatrix==True:
            for replicate, replimit in enumerate(limits):
                evol = mutate_seq(random_sequence[replicate], limit=replimit, limit_on=limit_on, matrix=sub_matrix[replicate])
                evolved_sequence.append(evol['sequence'])

        alis_by_f.append(evolved_sequence)
        ancestors_by_f.append(random_sequence)

    return(alis_by_f, ancestors_by_f)

# --- 2.2 With epistasis


def random_split_odd(n):
    """
    Randomly split the integer n into two integer halves.
    If n is odd, returns (floor, ceil) with 50% probability
    and (ceil, floor) the other 50%.
    If n is even, returns (n//2, n//2).
    """
    assert n > 0, "n should be a positive integer"
    left = n // 2       # floor for odd
    right = n - left    # ceil for odd
    if random.random() < 0.5:
        return (left, right)
    else:
        return (right, left)
    
def bounded_poisson(gamma, threshold):
    """
    Generates a random number from a Poisson distribution with mean `gamma`,
    ensuring it is less than `threshold`.
    """
    while True:
        value = np.random.poisson(gamma)
        if value <= threshold:
            return value
        
def get_matrix_changes_to_1_and_0(gamma, threshold,  equal_f_split, forced_changes_len):
    
    """
    Function to get the number of 0->1 and 1->0 changes in the matrix.

    Inputs:
    - gamma:
    - threshold:
    - equal_f_split (bool): 
        if True - get number of changes from poisson with gamma/2 and then multiply by 2 so that 0->1 and 1->0 are exactly the same
        if False - get number of changes from poisson with gamma, then split the number of changes between 0->1 and 1->0
        (if the number is odd - randomly choose 1->0 or 0->1 for the extra change)

    - forced_changes_len:
    
    Outputs:
    - n_changes_to_m:
    - to0:
    - to1
    """

    if equal_f_split and forced_changes_len%2 == 0:
        n_changes_to_m = bounded_poisson(gamma/2, threshold/2)*2
        n_changes_to_m=max(0, n_changes_to_m-forced_changes_len)
        if n_changes_to_m == 0:
            return(0,0,0)
        else:
            toall=int(n_changes_to_m/2)
            return(n_changes_to_m, toall, toall)
        
    elif equal_f_split and forced_changes_len%2 != 0:
        n_changes_to_m = bounded_poisson(gamma/2, threshold/2)*2
        n_changes_to_m=max(0, n_changes_to_m-forced_changes_len)
        if n_changes_to_m == 0:
            return(0,0,0)
        else:
            (to0,to1)=random_split_odd(n_changes_to_m)
            return(n_changes_to_m, to0, to1)
    else:
        n_changes_to_m = bounded_poisson(gamma, threshold)
        n_changes_to_m=max(0, n_changes_to_m-forced_changes_len)
        #get the number of 0->1 and 1->0 changes in the matrix 
        if n_changes_to_m % 2 == 0:
            to0=to1=int(n_changes_to_m/2)
        else:
            (to0,to1)=random_split_odd(n_changes_to_m)
        return(n_changes_to_m, to0, to1)


def mutate_seq_w_epistasis(sequence, matrix, neighbors={}, seq_evol_path=[], all_aa=None, limit = 5, limit_on='all_subs', gamma=0, equal_f_split=True):
    
    """
    Function that evolves (mutates) coding sequence(s).
    Only substitutions specified in the MATRIX are allowed to fix. 
    Args:
        sequence (str): nucleotide sequence to  evolve
        matrix (dict): dictionary of allowed substitutions
                        keys - amino acids
                        values - np.arrays with N elements each, where N is number of sites
                        in the translated sequence, with elements in [0,1], where 1 signifies 
                        that given amino acid (key) is allowed at this site (index in the array), 
                        0 - not allowed
        limit (int): number of substitutions/substitution attemts to happen before the function stops.
        limit_on (str) ['all_subs', 'all_attempts', 'syn_subs'] : which substitutions events or 
                        attemts to use to stop the evolution
        gamma (float): number of changes to the substitution matrix per nonsynonymous substitution
                       (can depend or not on the sequence length)

        NOTE ON LIMIT_ON=SYN_SUBS: there are ususally 0.25*seq_len synonymous sites (so dS=0.5 will
        correspond to 0.125*seq_len synonymous substitutions) 

    Epistasis algorithm:
    1. pick mutation 
    2. if nonsyn -> check its fitness in the neighbors 
    3. if good -> fix
    4. get the neighbors of the new sequence using the old matrix and check if 
       (a) they are in the neighbors and were already seen before
       (b) if (a) - whether their fitness corresponds to the fitness obtained using the old matrix
    5. if there are any incnsistencies in 4b -> change the matrix to accomodate (these are the forced changes to the matrix)
    6. draw the number of optional changes to the matrix (Poisson distributed with parameter gamma)
    7. if the number of optional changes to the matrix exceeds the number of already made forced changes 
       -> made optional-forced remaining changes to the matrix
       for every optional change:
       7.1 chck 

    Returns:
        evol - dictionary  with the sequence and number of substitutions/attempts. Keys:
            * sequence (str): evolved sequence
            * syn_count (int): number of synonymous substitutions
            * count_all (int): number of all mutation attmpts (including non-allowed)
            * count_good (int): number of allowed substitution events
        neighbors - dictionary with neighbors
        npmatrix - matrix of allowed (1) and forbidden substitutions 
        stats = (number_of_changes_to_matrix, total_forced_changes, seqs_already_in_neighbors_count, matrix_changes_failed_attempts_count)
    """

    count_good = 0
    #initialize gen code 
    standard_table = CodonTable.unambiguous_dna_by_name["Standard"]

    #get index of the last position in the nucleotide sequence
    seq_last_pos_ind=len(sequence)-1

    #split mutated sequence into codons
    seq_in_codons=textwrap.wrap(sequence, 3)
    aa_sequence=str(Seq(sequence).translate())

    #set how to track time
    limit_var={'all_subs':0, 'all_attempts':0, 'syn_subs':0}

    #transform matrix from dict to np.array
    if type(matrix)==dict:
        npmatrix=np.array(list(matrix.values()))
        #list of amino acids
        all_aa=list(matrix.keys()) 
    else:
        npmatrix=copy.deepcopy(matrix)
        if all_aa==None:
            #list of amino acids
            all_aa=['E', 'Q', 'R', 'F', 'N', 'A', 'V', 'D', 'Y', 'S', 'I', 'M', 'G', 'W', 'H', 'K', 'P', 'C', 'T', 'L']

    if seq_evol_path==[]:
        seq_evol_path.append(aa_sequence)
        intial_seq_evol_path_length=0
    else:
        intial_seq_evol_path_length=len(seq_evol_path)-1
    seqs_already_in_neighbors_count=0
    changes_to_matrix_count=0
    matrix_changes_failed_attempts_count=0
    #matrices=[npmatrix]
    total_forced_changes=0

    seqlen=len(seq_in_codons)
    n_aa=len(all_aa) #number of amino acids
    aaa_to_ind_dict=dict(zip(all_aa, range(n_aa)))
    ind_to_aaa_dict=dict(zip(range(n_aa), all_aa))
    

    if gamma!=0: #model epistasis 

        #matrix indices list (-1 accounts for the substraction of the last mutated position)
        #matrix_elements_indices=list(itertools.product(range(n_aa), range(seqlen-1)))
        matrix_elements_len=n_aa*seqlen

        #get the set of the indices of each site in the sequence
        all_aa_sites_set=set(range(seqlen))

        #get the neighbors of the original sequence and add them to the dictionary 
        for site in all_aa_sites_set:
            for aa in all_aa:
                neighbors[aa_sequence[:site]+aa+aa_sequence[site+1:]]=npmatrix[aaa_to_ind_dict[aa]][site]

    else: #no epistasis
        #changes_to_matrix_list=[]
        changes_to_matrix_count=None
        seqs_already_in_neighbors_count=None
        matrix_changes_failed_attempts_count=None
    

    while (limit_var[limit_on] < limit):

        #create list of nucleotides
        nucl = ["A","C","G","T"]

        #generate random mutation position
        mutation_pos = random.randint(0, seq_last_pos_ind)

        #get mutated codon and nucleotide
        mut_codon_pos=mutation_pos//3
        mut_pos_in_codon=mutation_pos%3

        #get original codon 
        oldcodon = seq_in_codons[mut_codon_pos]
        current_nuc_in_pos = oldcodon[mut_pos_in_codon]

        # remove current nuc from list of possible mutations
        nucl.remove(current_nuc_in_pos)

        #pick mutation
        mutation_nuc = random.choice(nucl)
        newcodon=oldcodon[:mut_pos_in_codon] + mutation_nuc + oldcodon[mut_pos_in_codon + 1:]
        
        #count mutation attempt
        limit_var['all_attempts'] += 1

        if newcodon in standard_table.stop_codons: #nonsense mutation -> don't fix 
            #print('nonsense_mut')
            continue
        else: 
            #get amino acid toward which the mutation has happened
            newmutation_aa=standard_table.forward_table[newcodon]
            #check if it's a missence mutation (change in aa)
            if newmutation_aa==standard_table.forward_table[oldcodon]: #synonymous mutation -> fix
                #synonymous mutation
                limit_var['syn_subs'] += 1
                #keep mutation 
                seq_in_codons[mut_codon_pos]=newcodon

            else: #non-synonymous mutation
                
                if gamma==0: #no epistasis
                    #check if it's a missence mutation (change in aa)
                    if npmatrix[aaa_to_ind_dict[newmutation_aa]][mut_codon_pos]==1:
                        # allowed sequence (Non-synonymous GOOD mutation)
                        count_good +=1
                        seq_in_codons[mut_codon_pos]=newcodon

                    else: #bad mutation -> don't fix
                        continue

                else: #with epistasis
                    #get potential new aa sequence
                    potential_aa_seq=aa_sequence[:mut_codon_pos]+newmutation_aa+aa_sequence[mut_codon_pos+1:]
                    if neighbors[potential_aa_seq]==1: # good mutation -> fix
                        #print('good mutation, site (col):', mut_codon_pos, newmutation_aa, 'row:', aaa_to_ind_dict[newmutation_aa])

                        # allowed sequence (Non-synonymous GOOD mutation)
                        count_good= count_good + 1
                        seq_in_codons[mut_codon_pos]=newcodon
                        
                        aa_sequence=copy.deepcopy(potential_aa_seq)
                        #check if any neighbors of the new sequence are in the neighbors dictionary 
                        # AND IF THEIR FITNESS CONTRADICTS THE FITNESS OBTAINED USING THE CURRENT UNMUTATED MATRIX 
                        # (IF YES, WE'LL HAVE TO FORCE THESE CHANGES INTO THE MATRIX FOR THE SAKE OF CONSISTENCY)
                        new_neighbors={}
                        aa_sites_wo_mutated=all_aa_sites_set-{mut_codon_pos}

                        forced_changes=[]
                        #forced_changes_new_fitness=[]
                        for site in aa_sites_wo_mutated:
                            for aa in all_aa:
                                pot_neigh=aa_sequence[:site]+aa+aa_sequence[site+1:]
                                if pot_neigh in neighbors: # and pot_neigh != aa_sequence:
                                    pot_neigh_existing_fitness=neighbors[pot_neigh]
                                    if pot_neigh_existing_fitness==npmatrix[aaa_to_ind_dict[aa]][site]: #neighbors and current matrix agrees 
                                        #print('neighbors and current matrix agrees, neigh: ', pot_neigh, 'current_seq:', aa_sequence, list(neighbors.keys()).index(pot_neigh), 'len neigh: ', len(neighbors))
                                        seqs_already_in_neighbors_count=seqs_already_in_neighbors_count+1
                                        continue
                                    else: #neighbors and current matrix doesn't agree -> need to change the matrix
                                        print('neighbors and current matrix doesnt agree, neigh fit: ', pot_neigh_existing_fitness, npmatrix[aaa_to_ind_dict[aa]][site], 'seq index on branch:', len(seq_evol_path), 'site (col):', site, aa, 'row:', aaa_to_ind_dict[aa], 
                                              #'\nprev', seq_evol_path[-1], '\ncurrent', aa_sequence, '\nneighbor', pot_neigh, changes_to_matrix_list, 
                                              )
                                        forced_changes.append([aaa_to_ind_dict[aa], site])
                                        changes_to_matrix_count=changes_to_matrix_count+1
                                        #changes_to_matrix_list.append([aaa_to_ind_dict[aa], site, 'forced'])
                                                                                
                                        #forced_changes_new_fitness.append(pot_neigh_existing_fitness)
                                    
                                        total_forced_changes=total_forced_changes+1
                                        #change the matrix
                                        npmatrix[aaa_to_ind_dict[aa], site]=pot_neigh_existing_fitness
                                        #matrices.append([npmatrix, 'forced'])
                                        
                                else:
                                    new_neighbors[pot_neigh]=npmatrix[aaa_to_ind_dict[aa]][site]

                        #forced changes were made with this mutation
                        forced_changes_len=len(forced_changes)

                        #update neighbors with forced changes in case we don't save optional changes to the matrix
                        if aa_sequence in seq_evol_path: # mutation towards already visited sequence -> can't change the matrix
                            print('mutation towards already visited sequence, current sequence #:', len(seq_evol_path), 'previously visited #:', seq_evol_path.index(aa_sequence))
                            seq_evol_path.append(aa_sequence)
                            #add the neighbors of the new sequence to the dictionary (using the new matrix)
                            # (except for the neighbors including just mutated site - they are already in the dictionary)
                            neighbors.update(new_neighbors) #update the neighbors
                            #new_neighboors_list.append(new_neighbors)
                            continue
                        
                        seq_evol_path.append(aa_sequence)
                        only_forced_new_neighbors=copy.deepcopy(new_neighbors)

                        #change matrix
                        n_changes_to_m, to0, to1 = get_matrix_changes_to_1_and_0(gamma, matrix_elements_len-20, equal_f_split, forced_changes_len)


                        if n_changes_to_m!=0:
                            #print('introduced', len(changes_to_matrix_list), 'changes to the matrix, indtoducing now: ', n_changes_to_m)
                            #make sure we don't change the mutation effects in the mutated positions (of other aa in this position)
                            matrix_wo_mutated_site = np.delete(npmatrix, mut_codon_pos, axis=1)  # Removes column 
                            aa_sites_wo_mutated_list=sorted(list(aa_sites_wo_mutated))
                            mutated_site_column = npmatrix[:, mut_codon_pos]

                            #get the indices of the 1s in the matrix ([row = aa, column = site])
                            locations1=np.argwhere(matrix_wo_mutated_site==1).tolist()
                            #get the indices of the 0s in the matrix ([row = aa, column = site])
                            locations0=np.argwhere(matrix_wo_mutated_site==0).tolist()

                            len0=len(locations0)
                            len1=len(locations1)

                            matrix_changes_failed_attempts_count_before=copy.copy(matrix_changes_failed_attempts_count)
                            if  forced_changes!=[]:
                                locations1= [loc1 for loc1 in locations1 if loc1 not in forced_changes]
                                locations0= [loc0 for loc0 in locations0 if loc0 not in forced_changes]

                            proceed_to_save_changes=True

                            changes_to_1=0

                            while changes_to_1 < to1:
                                #print('len loc 0: ', len(locations0))
                                #get the location to change from
                                try:
                                    change=random.sample(locations0, k=1)[0] #get the location to change from 0 to 1
                                    change_w_mut_site=[change[0], aa_sites_wo_mutated_list[change[1]]]
                                except (ValueError, IndexError) as err:
                                    print(err)
                                    #return(locations0, to1, aa_sites_wo_mutated_list, change, seq_evol_path,[aa_sites_wo_mutated, all_aa_sites_set])
                                #changes_to_matrix_attempts_list.append(change_w_mut_site)
                                #remove the change from the list of locations from the previous draws 
                                # (either because it was accepted or because it can't be changes because of existing neighbors) 
                                try:
                                    locations0.remove(change)
                                except ValueError:
                                    print('None of the changes to 0 are allowed because all of the neighbors are present in the matrix\n'
                                        'locations0', locations0, 'change:', change, 'forced:', forced_changes,  'n_changes', n_changes_to_m, 
                                          'to1', to1, 'changes_to_1',changes_to_1, 'count_good',count_good, 'len0', len0, 'len1', len1, 
                                          'failed attempts before', matrix_changes_failed_attempts_count_before, 'failed attempts now:', matrix_changes_failed_attempts_count)   
                
                                    proceed_to_save_changes=False
                                    to0=0
                                    break
                                    #if changes_to_1==0:
                                    #    to0=0
                                    #    proceed_to_save_changes=False
                                    #    break
                                    #else:
                                    #    to0=copy.copy(changes_to_1) #introduce exactly the amount of 1->0 changes as we did 0->1 changes
                                    #    break

                                #check if the change affects any of the already seen neighbors/sequences
                                changed_seq=aa_sequence[:change_w_mut_site[1]]+ind_to_aaa_dict[change_w_mut_site[0]]+aa_sequence[change_w_mut_site[1]+1:]
                                #check if the current sequence with the change is already in the neighbors 
                                # and if it's fitness is the same as we want to introduce to the matrix
                                if changed_seq in neighbors: 
                                    if neighbors[changed_seq]==1: #the change is in neighboors and it doesn't agree with the matrix
                                        #this should not be possible because all cases like this are already handled above
                                        #the change is allowed
                                        print('should not be possible, perhaps the sequence is not from the matrix, fitness in neighboors:', neighbors[changed_seq], 'current sequence #:', len(seq_evol_path)-intial_seq_evol_path_length, changed_seq==aa_sequence)
                                        changes_to_1=changes_to_1+1
                                        matrix_wo_mutated_site[change[0], change[1]]=1
                                        changes_to_matrix_count=changes_to_matrix_count+1
                                        #changes_to_matrix_list.append([change_w_mut_site[0], change_w_mut_site[1], 'to_1_should_not_be'] )
                                    else:
                                        matrix_changes_failed_attempts_count=matrix_changes_failed_attempts_count+1
                                        #print('the change contradicts existing neighbor, not allowed')
                                        continue #the change contradicts existing neighbor, not allowed
                                else:
                                    #the change is allowed
                                    changes_to_1=changes_to_1+1
                                    matrix_wo_mutated_site[change[0], change[1]]=1
                                    new_neighbors[changed_seq]=1
                                    changes_to_matrix_count=changes_to_matrix_count+1
                                    #changes_to_matrix_list.append([change_w_mut_site[0], change_w_mut_site[1], 'to_1'])
                            
                            changes_to_0=0

                            while changes_to_0 < to0:
                                #print('len loc 1: ', len(locations1))
                                #get the location to change from
                                try:
                                    change=random.sample(locations1, k=1)[0] #get the location to change from 0 to 1
                                    change_w_mut_site=[change[0], aa_sites_wo_mutated_list[change[1]]]
                                except (ValueError, IndexError) as err:
                                    print('None of the changes to 1 are allowed because all of the neighbors are present in the matrix\n')
                                    if changes_to_0==changes_to_1:
                                        proceed_to_save_changes=True
                                        break #and save changes to matrix and meighbors
                                    else:
                                        proceed_to_save_changes=False
                                        break

                                #changes_to_matrix_attempts_list.append(change_w_mut_site)
                                #remove the change from the list of locations from the previous draws 
                                # (either because it was accepted or because it can't be changes because of existing neighbors) 
                                locations1.remove(change)
                                #check if the change affects any of the already seen neighbors/sequences
                                changed_seq=aa_sequence[:change_w_mut_site[1]]+ind_to_aaa_dict[change_w_mut_site[0]]+aa_sequence[change_w_mut_site[1]+1:]
                                #check if the current sequence with the change is already in the neighbors 
                                # and if it's fitness is the same as we want to introduce to the matrix
                                if changed_seq in neighbors:
                                    if neighbors[changed_seq]==0: #this should not be possible because all cases like this are already handled above
                                        #the change is allowed
                                        print('should not be possible, perhaps the sequence is not from the matrix, fitness in neighboors:', neighbors[changed_seq],  'current sequence #:', len(seq_evol_path)-intial_seq_evol_path_length)
                                        changes_to_0=changes_to_0+1
                                        matrix_wo_mutated_site[change[0], change[1]]=0
                                        changes_to_matrix_count=changes_to_matrix_count+1
                                        #changes_to_matrix_list.append([change_w_mut_site[0], change_w_mut_site[1], 'to_0_should_not_be'])
                                    else:
                                        matrix_changes_failed_attempts_count=matrix_changes_failed_attempts_count+1
                                        #print('the change contradicts existing neighbor, not allowed')
                                        continue #the change contradicts existing neighbor, not allowed
                                else:
                                    #the change is allowed
                                    changes_to_0=changes_to_0+1
                                    matrix_wo_mutated_site[change[0], change[1]]=0
                                    new_neighbors[changed_seq]=0
                                    changes_to_matrix_count=changes_to_matrix_count+1
                                    #changes_to_matrix_list.append([change_w_mut_site[0], change_w_mut_site[1], 'to_0'])

                            if proceed_to_save_changes:
                                # Add the column back in its original position
                                npmatrix = np.insert(matrix_wo_mutated_site, mut_codon_pos, mutated_site_column, axis=1)
                                #add the neighbors of the new sequence to the dictionary (using the new matrix)
                                # (except for the neighbors including just mutated site - they are already in the dictionary)
                                if new_neighbors=={}:
                                    print('no new neighbors for nonsyn mutation #', count_good)
                                    #new_neighboors_list.append(new_neighbors)
                                else:
                                    neighbors.update(new_neighbors) #update the neighbors
                                    #new_neighboors_list.append(new_neighbors)
                                continue
                            else:
                                if new_neighbors=={}:
                                    print('proceed_to_save_changes=False, no new neighbors for nonsyn mutation #', count_good)
                                    #new_neighboors_list.append(new_neighbors)
                                else:
                                    neighbors.update(only_forced_new_neighbors) #update the neighbors
                                    #new_neighboors_list.append(new_neighbors)
                                continue
                        else:
                            if new_neighbors=={}:
                                print('no new neighbors for nonsyn mutation #', count_good)
                                #new_neighboors_list.append(new_neighbors)
                            else:
                                neighbors.update(only_forced_new_neighbors) #update the neighbors
                                #new_neighboors_list.append(new_neighbors)

                    else: #bad mutation -> don't fix
                        continue

        #update the count of all substitutions that happened        
        limit_var['all_subs'] = count_good + limit_var['syn_subs'] 

    return({'sequence':"".join(seq_in_codons),
            'count_syn':limit_var['syn_subs'],
            'count_good':count_good,
            'count_all':limit_var['all_attempts']}, neighbors, npmatrix, seq_evol_path,
            #changes_to_matrix_list, changes_to_matrix_list_mutationwise, new_neighboors_list, matrices,
            (changes_to_matrix_count, total_forced_changes, seqs_already_in_neighbors_count,matrix_changes_failed_attempts_count))


# --- 3. Generate and evolve tree

def simulate_starlike_tree(n_leaves, starlike_limit='gammaFitAll', exp_rate=0.05349, length_scale=1):
    """
    Function to generate a star like tree (N sequences independently 
    evolving from 1 ancestor).
    Args:
        n_leaves (int): Number of leaf nodes in the tree.
        starlike_limit (str): way to define the branch lengths of the tree. One of the following:
            - gammaTheor - parameters of gamma distribution are shape=2*np.log(n_leaves), scale=exp_rate.
                The average number of internal nodes between the root and the leaf are of the order of 
                O(ln(n_leaves)) or 2*ln(n_leaves) - from Blum & Francois, 2005, section 2.1 
                (https://doi.org/10.1016/j.mbs.2005.03.003).
            - gammaTheorAdj - parameters of gamma distribution are shape=2*np.log(n_leaves)-2, scale=exp_rate.
                Same as in gammaTheor, but -2 added for a better fit to the data (no_scaling mode). 
            - gammaFitAll - the parameters of gamma distribution of the root-to-leaf lengths
                was fitted from the mix of empirical root-to-leaf lengths of 1000 trees with 300 leaves each of
                each of the following run modes:
                no_scaling, 
                shortleaves (length_scale=2.3, exp_rate=0.1, scale_factor=0, shortleaves='exp_node_order_rate'),
                longleaves(length_scale=0.05, exp_rate=0.05, scale_factor=1, shortleaves='exp_node_order_rate_rev').
            - gammaFitNoScale - the parameters of gamma distribution of the root-to-leaf lengths
                was fitted from empirical root-to-leaf lengths of 1000 trees with 300 leaves each of
                no_scaling trees simulation (default parameters)
            - normalFitAll - the parameters of normal distribution (mean and st. dev) of the root-to-leaf lengths
                was fitted from empirical root-to-leaf lengths of 1000 trees with 300 leaves each of
                no_scaling trees simulation (default parameters)

            Recommended: "gammaFitAll" - most universal parameter set. The Gamma distribution is used here since
                    it describes the distribution of k exponentially distributed random variables 
                    (branch lengths), where k is the number of nodes between the root and each leaf.
                    For a better comparison with no_scaling trees "gammaFitNoScale" is recommended.

        exp_rate (np.float): rate parameter of the exponential distribution to use for calculation
                            of number of internal nodes per leaf if starlike_limit=='gammaTheor' or 
                            'gammaTheorAdj'.
        length_scale (np.float): factor by which to isometrically scale the branch lengths on the whole tree

    Returns:
        star like tree in the ete3.Tree format
    """

    #get the tree instance
    t=Tree()
    t.dist=0
    #get the divergence limit distribution for each leaf
    if starlike_limit=='gammaTheor':
        limits=np.random.gamma(2*np.log(n_leaves), exp_rate, size=n_leaves)
    elif starlike_limit=='gammaTheorAdj':
        limits=np.random.gamma(2*np.log(n_leaves)-2, exp_rate, size=n_leaves)
    elif starlike_limit=='gammaFitAll':
        gamma_params=(6.066038229821358, 0.10460460394115609)
        limits=np.random.gamma(gamma_params[0], gamma_params[1], size=n_leaves)
    elif starlike_limit=='normalFitAll':
        normal_params=(0.6345355265223748, 0.2643191325973886)
        limits=np.random.normal(normal_params[0], normal_params[1], size=n_leaves)
        #make sure there are no negative values
        limits[limits < 0] = 0
    elif starlike_limit=='gammaFitNoScale':
        gamma_params=(5.639749895152642, np.float64(0.09262828362453954))
        limits=np.random.gamma(gamma_params[0], gamma_params[1], size=n_leaves)
    
    #populate the tree (node names are integers, branch lengths are from the distribution above)
    for index, limit in enumerate(limits*length_scale):
        t.add_child(name=str(index), dist=limit)
    return t

def simulate_tree_with_depth_scaled_branch_lengths(n_leaves, scale_factor=0, length_scale=1, t=None, 
                                                   distribution='exp', exp_rate=0.05349, shortleaves=None, 
                                                   starlike=False, starlike_limit='gammaFitAll'):
    """
    Simulates a phylogenetic tree with branch lengths drawn from an exponential distribution,
    scaled to decrease with increasing depth from the root.
    The default is unconstrained branch lengths that follow exponential distribution with scale
    parameter (=mean) of 0.0535 (estimated from vertebrate trees from ensembl).
    The resulting tree topology is random (it's NOT a birth-death or Yule process, since they are more imbalanced).
    Args:
        n_leaves (int): Number of leaf nodes in the tree.
        scale_factor (float): Factor to scale branch lengths by depth (higher means faster decay).
                              It's only actually used if shortleaves=='exp_node_order_scale_rev' 
                              or 'exp_node_order_rate_rev'
        length_scale (float): factor by which to isometrically scale the branch lengths on the whole tree
        t (ete3.Tree): preset tree topology (optional)
        distribution (str): name of the distribution to sample the branch length from. 
                            Exponential by default.
        exp_rate (float): Rate parameter for the exponential distribution.
        shortleaves (str): option to scale the branch lengths with tree depth. Options:
            Mechanism: scaling of the rate of exponential distribution

                Branch length decreases from root to leaf:
                - exp_node_order_rate (as a function of node order): MAIN FOR SHORTLEAVES
                    parameters to use: length_scale=2.3, exp_rate=0.1, scale_factor=0
                    Distance range with gamma=0: 0-0.8
                    can also use length_scale=2, exp_rate=0.05, scale_factor=0
                    for Distance range with gamma=0: 0-0.6
                - exp_dist_root_rate (as a fucnction of node depth)
                
                Branch length increases from root to leaf:
                - exp_node_order_rate_rev (as a function of node order): MAIN FOR LONGLEAVES
                    parameters to use: length_scale=0.05, exp_rate=0.05, scale_factor=1
                    Distance range with gamma=0 - 0-0.8
                - exp_dist_root_rate_rev (as a fucnction of node depth)
                
            Mechanism: scaling of the final branch length - 
            the rate of exponential distribution doesn't change
                - exp_node_order_scale_rev (as a fucnction of node depth)
                    parameters to use: length_scale=0.08, exp_rate=0.05, scale_factor = 1.2 

            If shortleaves==None or any other value, no scaling of branch lengths will be applied
    
        starlike (bool or 'no_tree'==True): set to true if desired simulation mode is to have all leaves 
                        originating from the root (starlike tree or no tree)
        starlike_limit (str: 'gammaFitAll', 'gammaTheor', 'gammaTheorAdj', 'gammaFitNoScale',
                         'normalFitAll'): see simulate_starlike_tree() for a more detailed explanation.
                         Default and recommended: 'gammaFitAll'.

    Returns:
        Tree: A phylogenetic tree with (possibly) depth-scaled branch lengths.
    """
    # Step 1: Generate a random tree topology (if the topology not given as an input)
    if starlike==True or starlike=='notree' or starlike=='no_tree':
        return(simulate_starlike_tree(n_leaves, starlike_limit=starlike_limit, 
                                      exp_rate=exp_rate, length_scale=length_scale))
    else:
        if t==None: #if no predefined topology is set generate a random tree
            t = Tree()
            t.populate(n_leaves)
    t.dist=0
    
    #options too scale branch lengths with tree depth 
    # branches longer near the root, shorter near leaves as a function of node order
    # scaling of the rate of exponential distribution
    if shortleaves=='exp_node_order_rate':
        # Step 2: Assign branch lengths based on depth
        for index, node in enumerate(t.traverse()):  # Traverse all nodes, including internal nodes
            if not node.is_root():  # Skip the root (root branch length is often undefined)
                node.name=str(index)
                depth = node.get_distance(t) # Distance of the node from the root
                node_order=node.get_distance(t, topology_only=True)
                branch_length = length_scale * scipy.stats.expon.rvs(0, exp_rate/((1+scale_factor)*node_order),  size=1)
                node.dist = branch_length 

    elif shortleaves=='exp_dist_root_rate':
        for index, node in enumerate(t.traverse()):  # Traverse all nodes, including internal nodes
            if not node.is_root():  # Skip the root (root branch length is often undefined)
                node.name=str(index)
                depth = node.get_distance(t)  # Distance of the node from the root
                node_order=node.get_distance(t, topology_only=True)
                if depth==0:
                    branch_length = length_scale * scipy.stats.expon.rvs(0, exp_rate,  size=1)
                else:
                    branch_length = length_scale * scipy.stats.expon.rvs(0, exp_rate/((1+scale_factor)*depth),  size=1)
                node.dist = branch_length
                #print(branch_length)
                
    # branches longer near the root, shorter near leaves as a function of node depth 
    # scaling of the rate of exponential distribution
    elif shortleaves=='exp_dist_root_rate_rev': #DON'T USE
        for index, node in enumerate(t.traverse()):  # Traverse all nodes, including internal nodes
            if not node.is_root():  # Skip the root (root branch length is often undefined)
                node.name=str(index)
                depth = node.get_distance(t)  # Distance of the node from the root
                node_order=node.get_distance(t, topology_only=True)
                if depth==0:
                    branch_length = length_scale * scipy.stats.expon.rvs(0, exp_rate,  size=1)
                else:
                    branch_length = length_scale * scipy.stats.expon.rvs(0, exp_rate*(1+scale_factor)*depth,  size=1)
                node.dist = branch_length
                #print(branch_length)

    # branches shorter near the root, longer near leaves as a function of node order
    # scaling of the rate of exponential distribution
    elif shortleaves=='exp_node_order_rate_rev':
        # Step 2: Assign branch lengths based on depth
        for index, node in enumerate(t.traverse()):  # Traverse all nodes, including internal nodes
            if not node.is_root():  # Skip the root (root branch length is often undefined)
                node.name=str(index)
                depth = node.get_distance(t) # Distance of the node from the root
                node_order=node.get_distance(t, topology_only=True)
                branch_length = length_scale * scipy.stats.expon.rvs(exp_rate*scale_factor*node_order,  size=1)
                node.dist = branch_length
    # branches shorter near the root, longer near leaves as a function of node order
    # scaling of the final branch length - the rate of exponential distribution doesn't change
    elif shortleaves=='exp_node_order_scale_rev':
        # Assign branch lengths based on depth
        for index, node in enumerate(t.traverse()):  # Traverse all nodes, including internal nodes
            if not node.is_root():  # Skip the root (root branch length is often undefined)
                node.name=str(index)
                depth = node.get_distance(t) # Distance of the node from the root
                node_order=node.get_distance(t, topology_only=True)
                branch_length = length_scale * scipy.stats.expon.rvs(exp_rate,  size=1)
                node.dist = branch_length * (1+(scale_factor* depth))

    # the branch lengths are +- the same lenth along the tree - no branch length dependence on the distance from root            
    else:
        #different possible distributions (all parameters are fitted from 100 Ensembl vertebrates gene trees)
        if distribution=='exp':
            if exp_rate==None:
                params=(0.0, 0.05349375682793601)
            else:
                params=(0.0, exp_rate)
            distr_function=scipy.stats.expon.rvs
        elif distribution=='weibull':
            #params=(0.6757823412095053, 0, 0.03302498014779158) #this is a version where i didn't remove branches with length 0
            params=(0.7041581555952987, 0, 0.04071410907195197)
            distr_function=scipy.stats.weibull_min.rvs
        elif distribution=='lognorm':
            params=(1.5213963419057293, 0, 0.019315917612581075)
            distr_function=scipy.stats.lognorm.rvs
        elif distribution=='gamma':
            params=(0.6057245194180889, 0, 0.08831367249145984)
            distr_function=scipy.stats.gamma.rvs

        for index, node in enumerate(t.traverse()):  # Traverse all nodes, including internal nodes
            if not node.is_root():  # Skip the root (root branch length is often undefined)
                node.name=str(index)
                depth = node.get_distance(t)  # Distance of the node from the root
                branch_length = length_scale * distr_function(*params, size=1)
                node.dist = branch_length / (1 + scale_factor * depth)  # Scale by depth (not used here)

    return t


def evolve_tree(sequence, matrix, tree, neighbors={},limit_on='all_subs', gamma=0, equal_f_split=True, universal_neighbors=True):
    """
    Function that evolves sequences according to a gene tree (TREE). 
    The branch lengths are in substitutions per site (syn + nonsyn).
    They are multiplied by the length of the sequence in nt to get the 
    limiting number of substitutions when the simulation should stop - 
    closest integer.

    Args:
        sequence (str): nucleotide sequence to  evolve
        matrix (dict or np.array)): dictionary of allowed substitutions
                        keys - amino acids
                        values - np.arrays with N elements each, where N is number of sites
                        in the translated sequence, with elements in [0,1], where 1 signifies 
                        that given amino acid (key) is allowed at this site (index in the array), 
                        0 - not allowed;
                        if np.array (values only), the shape should be 20 x SEQ_LEN, in that case 
                        the amino acids are provided inside this function

        tree (Tree): gene tree to use for evolution
        limit_on (str): 'all_subs' or 'all_attempts'
        gamma (float): gamma parameter for epistasis, 0 = no epistasis (default)
        equal_f_split (bool): True - equal frequency of substitutions at each site with gamma/2 
                                parameter for Poisson for 0 and for 1, 
                                False - roughly equal frequency of substitutions at each site with 
                                gamma parameter for Poisson and the number of substitutions distributed 
                                to 0 and 1 almost equaly (if the drawn number is odd)
    
    Returns:
        list of sequences on the leaves of the tree
        statistics (actual dn, ds, and mutation attempts)
    
    """
    # allow for np.array input matrix format 
    if type(matrix)==dict:
        aa_rows=list(matrix.keys())
        matrix=np.array(list(matrix.values()))
    else:
        aa_rows=['E', 'Q', 'R', 'F', 'N', 'A', 'V', 'D', 'Y', 'S', 'I', 'M', 'G', 'W', 'H', 'K', 'P', 'C', 'T', 'L']

    leaves = []
    nonsyn_subs=[]
    syn_subs=[]
    subs_attempts=[]
    #set root sequence
    tree.sequence=sequence
    tree.subs_matrix=matrix
    tree.syn_subs=0
    tree.nonsyn_subs=0
    tree.subs_attempts=0
    #tree.changes_to_matrix=[]
    #get the length of the sequence in nt
    seqlen=len(sequence)
    statslist=[]

    if gamma==0: #no episatsis
        for node in tree.traverse("levelorder"):
            #skip root evolution
            if node.is_root():
                continue
            else:
                # evol - a dict with the sequence and number of substitutions/attempts. Keys: sequence, count_syn, count_good, count_all
                # for non-epistasis case other outputs are None or empty
                evol, neighbors, npmatrix, seq_path, stats = mutate_seq_w_epistasis(node.up.sequence, matrix, neighbors=neighbors, 
                                                                          all_aa=aa_rows, limit=round(node.dist*seqlen, 0), 
                                                                          limit_on=limit_on, gamma=gamma, equal_f_split=equal_f_split)
                node.sequence=evol['sequence']
                node.syn_subs=node.up.syn_subs+evol['count_syn']
                node.nonsyn_subs=node.up.nonsyn_subs+evol['count_good']
                node.subs_attempts=node.up.subs_attempts+evol['count_all']
                if node.is_leaf():
                    leaves.append(node.sequence)
                    nonsyn_subs.append(node.nonsyn_subs)
                    syn_subs.append(node.syn_subs)
                    subs_attempts.append(node.subs_attempts)

    elif universal_neighbors: #the dict of neighboors is common for all nodes across the tree
        tree.seq_path=[]
        for node in tree.traverse("levelorder"):
            #skip root evolution
            if node.is_root():
                continue
            else:
                #print('new branch')
                # evol - a dict with the sequence and number of substitutions/attempts. Keys: sequence, count_syn, count_good, count_all
                # neighbors - dictionary with neighbors
                # npmatrix - matrix of allowed (1) and forbidden substitutions 
                # stats = (number_of_changes_to_matrix, forced_changes_count, seqs_already_in_neighbors_count, matrix_changes_failed_attempts_count)
                evol, neighbors, npmatrix, seq_path, stats = mutate_seq_w_epistasis(node.up.sequence, copy.deepcopy(node.up.subs_matrix), 
                                                                                    neighbors=neighbors, seq_evol_path=copy.deepcopy(node.up.seq_path), 
                                                                                    all_aa=aa_rows, limit=round(node.dist*seqlen, 0), 
                                                                                    limit_on=limit_on, gamma=gamma, equal_f_split=equal_f_split)

                node.sequence=evol['sequence']
                node.syn_subs=node.up.syn_subs+evol['count_syn']
                node.nonsyn_subs=node.up.nonsyn_subs+evol['count_good']
                node.subs_attempts=node.up.subs_attempts+evol['count_all']
                node.subs_matrix=copy.deepcopy(npmatrix)
                node.seq_path=copy.copy(seq_path)
                #node.changes_to_matrix=node.up.changes_to_matrix+chmatr
                #node.neighbors=copy.deepcopy(neighbors)
                statslist.append(stats)
                if node.is_leaf():
                    leaves.append(node.sequence)
                    nonsyn_subs.append(node.nonsyn_subs)
                    syn_subs.append(node.syn_subs)
                    subs_attempts.append(node.subs_attempts)
                    print('leaf: ', node.name, '# neighbors: ',  len(neighbors), 'number_of_changes', stats[0], 'forced_changes_count', stats[1], 'seqs_already_in_neighbors_count', stats[2], 'nonsyn_subs:', node.nonsyn_subs)
                else:
                    print('node: ', node.name, '# neighbors: ',  len(neighbors), 'number_of_changes', stats[0], 'forced_changes_count', stats[1],'seqs_already_in_neighbors_count', stats[2], 'nonsyn_subs:', node.nonsyn_subs)
                    
        print('total neighbors:',  len(neighbors))

    else:  #the dict of neighboors is lineage specific
        tree.neighbors=copy.deepcopy(neighbors)
        tree.seq_path=[]
        for node in tree.traverse("levelorder"):
            #skip root evolution
            if node.is_root():
                continue
            else:
                #print('new branch')
                # evol - a dict with the sequence and number of substitutions/attempts. Keys: sequence, count_syn, count_good, count_all
                # neighbors - dictionary with neighbors
                # npmatrix - matrix of allowed (1) and forbidden substitutions 
                # stats = (number_of_changes_to_matrix, forced_changes_count, seqs_already_in_neighbors_count, matrix_changes_failed_attempts_count)
                evol, neighbors, npmatrix, seq_path, stats = mutate_seq_w_epistasis(node.up.sequence, copy.deepcopy(node.up.subs_matrix), 
                                                                           neighbors=copy.deepcopy(node.up.neighbors), seq_evol_path=copy.deepcopy(node.up.seq_path), 
                                                                           all_aa=aa_rows, limit=round(node.dist*seqlen, 0), 
                                                                           limit_on=limit_on, gamma=gamma, equal_f_split=equal_f_split)
                node.sequence=evol['sequence']
                node.syn_subs=node.up.syn_subs+evol['count_syn']
                node.nonsyn_subs=node.up.nonsyn_subs+evol['count_good']
                node.subs_attempts=node.up.subs_attempts+evol['count_all']
                #node.changes_to_matrix=node.up.changes_to_matrix+chmatr
                node.neighbors=copy.deepcopy(neighbors)
                node.subs_matrix=copy.deepcopy(npmatrix)
                node.seq_path=copy.copy(seq_path)
                statslist.append(stats)
                
                if node.is_leaf():
                    leaves.append(node.sequence)
                    nonsyn_subs.append(node.nonsyn_subs)
                    syn_subs.append(node.syn_subs)
                    subs_attempts.append(node.subs_attempts)
                    print('leaf: ', node.name, '# neighbors: ',  len(node.neighbors), 'number_of_changes', stats[0], 'forced_changes_count', stats[1], 'seqs_already_in_neighbors_count', stats[2], 'nonsyn_subs:', node.nonsyn_subs)
                else:
                    print('node: ', node.name, '# neighbors: ',  len(node.neighbors), 'number_of_changes', stats[0], 'forced_changes_count', stats[1], 'seqs_already_in_neighbors_count', stats[2], 'nonsyn_subs:',  node.nonsyn_subs)
    

    return(leaves, nonsyn_subs, syn_subs, subs_attempts, tree, statslist)


# --- 4. Get stats

def fast_sample_unique_pairs(n, k):
    seen = set()
    pairs = []
    while len(pairs) < k:
        a = random.randint(0, n - 1)
        b = random.randint(0, n - 1)
        if a == b:
            continue
        pair = tuple(sorted((a, b)))  # enforce order so (a, b)  (b, a)
        if pair not in seen:
            seen.add(pair)
            pairs.append(pair)
    return pairs

def to_uint8_matrix(strings):
    """Encode strings to a 2D uint8 array: shape = (N, L)"""
    L = len(strings[0])
    A = np.empty((len(strings), L), dtype=np.uint8)
    for i, s in enumerate(strings):
        A[i] = np.frombuffer(s.encode(), dtype=np.uint8)
    return A

def hamming_pairs_strings(seqs, pairs, normalized=True):
    """
    seqs: list[str], all equal length
    pairs: list[tuple[int,int]] of indices
    normalized: True -> fraction, False -> count
    """
    L = len(seqs[0])
    out = np.empty(len(pairs), dtype=np.float32)

    # lazy per-sequence cache (encode once per index at most)
    cache = {}  # idx -> bytes
    def bseq(i):
        bi = cache.get(i)
        if bi is None:
            bi = seqs[i].encode()  # fast ASCII/UTF-8 bytes
            cache[i] = bi
        return bi

    for t, (i, j) in enumerate(pairs):
        bi, bj = bseq(i), bseq(j)
        # bytewise mismatch count; zip over bytes is implemented in C
        diff = sum(x != y for x, y in zip(bi, bj))
        out[t] = (diff / L) if normalized else diff

    return out

def get_distance_array(sequence_list, fraction=1.0, upper=True):
    """
    Function that calculates pairwise distances between sequences in a list.

    IMPORTANT: pairwise distances calculated here are only valid if the sequences 
                don't have any gaps.  All sequences should be of the same length! 
                Otherwise, a standalone function hamming_distance_multiple_ali_universal.py 
                should be used to get a pairwise distance matrix.
                Pairwise distances are divided by the seqeunce length.
                This function doesn't remove gaps.
                
    Input:
    - list of sequeces (strings)
    - fraction of possible unique pairs to sample
    - upper (bool) if True, sequence_list will be converted to uppercase, 
             for the sake of time-efficiency, can be turned off if
             the sequences are already in uppercase.

    Output:
    - np.ndarray of pairwise distances
    """
    nseqs = len(sequence_list)
    total_pairs = nseqs * (nseqs - 1) // 2

    if upper:
        seqlist=[i.upper() for i in sequence_list]
        sequence_list=seqlist

    if not (0 < fraction <= 1):
        raise ValueError("fraction must be between 0 and 1")

    if fraction == 1.0:
        # use all possible pairs
        #to numeric (for faster distance calculation with numpy)
        A = to_uint8_matrix(sequence_list)
        #pairwise normalized Hamming distances (proportion of mismatches)
        frac_dist_evolved = pdist(A, metric='hamming')  # length N*(N-1)//2

    else:
        num_sampled_pairs = max(1, int(total_pairs * fraction))
        #we need this function because we need unique pairs, not unique indices
        sampled_pairs = fast_sample_unique_pairs(nseqs, num_sampled_pairs)
        frac_dist_evolved=hamming_pairs_strings(sequence_list, sampled_pairs)

    return frac_dist_evolved


def get_dnds_dist_dim_stats_from_seq(evolved_sequence:list, dist_to_file=None,
                                     win_size_perc=0.4, dim_only=False, out_dist=False, nt=True, 
                                     dim_out=None, dim_stats_out=False, plotdim=False, distvar=False, maxdist=False,
                                     dim_range_from_data=False):
    """
    Function that takes a simulated "protein family" of nt sequences
    and calculates the following statistics:
    - average pn/ps between the leaf (final) sequences (if dim_only==False)
      keep in mind that this pn/ps isn't corrected for multiple substitutions 
      and is inaccurate on large distances. It shouldn't be used for any analysis.
      dn/ds from the tree or calculated using PAML should be used instead.
    - *average pairwise amino acid between the leaf (final) sequences
    - *dimensionality  (for evolved sequences)

    *IMPORTANT: pairwise distances calculated here are only valid if the sequences 
                don't have any gaps (all of the same length). Otherwise, a standalone 
                function hamming_distance_multiple_ali_universal.py should be used to get
                a pairwise distance matrix. This function doesn't remove gaps.

    If dim_only and out_dist are both True, the first output in the list of pairwise
    distances instead on the average dnds.
    
    Args:
        evolved_sequence (list): list of sequences from the same protein family / tree leaves
        dist_to_file (None or str): name (suffix) of the file to write the pairwise distance 
        matrix, set to None to avoid recording the matrix (default). 
    """

    frac_dnds_evolved=[]
    nonsyn_only_count=0
    if nt:
        evolved_aa=[str(Seq(eaa).translate()) for eaa in  evolved_sequence]
    else:
        evolved_aa=evolved_sequence
        dim_only=True #if input is amino acids, calculating dn/ds is impossible
    nseqs=len(evolved_sequence)
    arrlen= (nseqs*nseqs-nseqs)/2 #number of dissimilar pairwise distances

    if dim_out:
        out_file=True
    else:
        out_file=False

    if dim_only: #only compare the dimensionality
        frac_dist_evolved=get_distance_array(evolved_aa, upper=False)
        distall_evolved=np.mean(frac_dist_evolved)
        dim_evolved=seqsp.max_k((frac_dist_evolved, arrlen), nparray=False, from_file=False, 
                                flat=True, plot=plotdim, win_size_perc=win_size_perc, out_file=out_file, 
                                fname=dim_out, ci_r2_out_flat=dim_stats_out, reg_range_from_data=dim_range_from_data)
        if dist_to_file:
            distdf=pd.DataFrame.from_records(np.triu(squareform(frac_dist_evolved))).round(5)
            #record matrix to file
            with open('%s.pdistm' % (dist_to_file), 'w+') as outm:
                distdf.to_csv(outm, index=False, header=False)

        #allow outputting distance variance and maximum distance 
        if distvar and maxdist:
            distall_evolved_var=np.var(frac_dist_evolved)
            distout=(distall_evolved, distall_evolved_var, np.max(frac_dist_evolved))
        elif maxdist:
            distout=(distall_evolved, np.max(frac_dist_evolved))
        elif distvar:
            distall_evolved_var=np.var(frac_dist_evolved)
            distout=(distall_evolved, distall_evolved_var)
        else:
            distout=distall_evolved

        if out_dist:
            return(frac_dist_evolved, distout, dim_evolved)
        else:
            return(distout, dim_evolved)
    
    else: #only compare the leaf (evolved sequences with each other but not with the ancestor)
        frac_dist_evolved=get_distance_array(evolved_aa, upper=False)
        comb_ind=itertools.combinations(range(nseqs), 2)
        for ind, s in enumerate(comb_ind):
            try:
                frac_dnds_evolved.append(dnds.pnps(evolved_sequence[s[0]], evolved_sequence[s[1]]))
            except ZeroDivisionError:
                nonsyn_only_count=nonsyn_only_count+1
        distall_evolved=np.mean(frac_dist_evolved)
        dnds_evolved=np.mean(frac_dnds_evolved)
        dim_evolved=seqsp.max_k((frac_dist_evolved, arrlen), nparray=False, from_file=False, 
                                flat=True, plot=plotdim, win_size_perc=win_size_perc, out_file=out_file, 
                                fname=dim_out, ci_r2_out_flat=dim_stats_out, reg_range_from_data=dim_range_from_data)
        if dist_to_file:
            distdf=pd.DataFrame.from_records(np.triu(squareform(frac_dist_evolved))).round(5)
            #record matrix to file
            with open('%s.pdistm' % (dist_to_file), 'w+') as outm:
                distdf.to_csv(outm, index=False, header=False)

        #allow outputting distance variance and maximum distance 
        if distvar and maxdist:
            distall_evolved_var=np.var(frac_dist_evolved)
            distout=(distall_evolved, distall_evolved_var, np.max(frac_dist_evolved))
        elif maxdist:
            distout=(distall_evolved, np.max(frac_dist_evolved))
        elif distvar:
            distall_evolved_var=np.var(frac_dist_evolved)
            distout=(distall_evolved, distall_evolved_var)
        else:
            distout=distall_evolved

        if nonsyn_only_count!=0:
            print(nonsyn_only_count, 'dnds value ommited because of the present nonsyn subs, but no syn subs')
        return(dnds_evolved, distout, dim_evolved)


def simulate_evolve_tree_get_stats(symparams:list, ntseqlen, aaseqlen, n_leaves, frac_allowed, exp_rate=0.05, shortleaves=False, 
                                   simtree=None, newtree=True, dim_only=True, outtree=None, outfasta=None, 
                                   scale_factor=0, out_dist=False, verbose=True, include_internal=False, 
                                   dist_to_file=None, win_size_perc=0.4, dim_range_from_data=False):
    
    """
    Function to simulate evolution of a protein family given one value of fraction
    of allowed aa substitutions. It can generate a new tree, ancestor sequence, 
    evolve it into N_LEAVES proteins and calculate the dimensionality, average
    pairwise distance and dn/ds (from tree).

    Args:
        include_internal (bool): if False - dimensionality, distance and (optionally) dn/ds
            are only calculated for the leaves on the tree (extant proteins). The output is 
            then a tuple of 2 or 3 values ([dnds_evolved], distall_evolved, dim_evolved).
            If True - dimensionality, distance and (optionally) dn/ds are calculated for the 
            leaves only (first 2 or 3 values of the output), internal nodes only (second 2 or 3 
            values of the output) and for the mix of internal nodes and leaves (the last set of 
            values in the output tuple). Default: False.
        dist_to_file (None or str): name (suffix) of the file to write the pairwise distance 
            matrix, set to None to avoid recording the matrix (default).  
    
    """

    if newtree: #simulate a new tree for each replicate
        simtree = simulate_tree_with_depth_scaled_branch_lengths(n_leaves, scale_factor=scale_factor,
                                                                 length_scale=float(symparams[1]), 
                                                                 distribution=symparams[2], exp_rate=exp_rate, 
                                                                 shortleaves=shortleaves, 
                                                                 starlike=symparams[0], starlike_limit=symparams[2])
        
    matrix= generate_matrix_AA(aaseqlen, fraction=frac_allowed)
    random_sequence = generate_nt_seq(ntseqlen, 1, seqfrom='matrix', matrix=matrix)
    leaves, nonsyn_subs, syn_subs, subs_attempts, tree, statslist = evolve_tree(random_sequence, matrix, simtree,
                                                                                 neighbors={}, limit_on='all_subs', gamma=float(symparams[3]), 
                                                                                 equal_f_split=True, universal_neighbors=True)
    if outfasta:
        #write leaves as fasta file
        with open(outfasta, 'w') as outf:
            outf.write(''.join(['>'+str(ind)+'\n'+evseq+'\n' for ind, evseq in enumerate(leaves)]))
    if outtree:
        #write tree
        with open(outtree, 'wb') as out_tree:
            pickle.dump(tree, out_tree)

    if include_internal and symparams[0]=='tree': #only include internal nodes if tree is not starlike
        intnodes=[]
        result=[]
        #get internal node sequences
        for node in tree.traverse("levelorder"):
            if node.is_leaf():
                continue
            else:
                intnodes.append(node.sequence)

        #get dim and average dist of leaves only
        #set names for pdistm files
        if dist_to_file:
            dist_to_file_l=dist_to_file+'_leaves'
            dist_to_file_i=dist_to_file+'_anc'
            dist_to_file_li=dist_to_file+'_leaves_anc'
        else:
            dist_to_file_l=dist_to_file_i=dist_to_file_li=dist_to_file

        result_l =get_dnds_dist_dim_stats_from_seq(leaves, win_size_perc=win_size_perc, dist_to_file=dist_to_file_l,
                                                   dim_only=dim_only, out_dist=out_dist, dim_range_from_data=dim_range_from_data)
        result.extend(result_l)
        #get dim and average dist of internal nodes only
        result_i =get_dnds_dist_dim_stats_from_seq(intnodes, win_size_perc=win_size_perc, dist_to_file=dist_to_file_i,
                                                   dim_only=dim_only, out_dist=out_dist, dim_range_from_data=dim_range_from_data)
        result.extend(result_i)
        #get dim and average dist of leaves with internal nodes 
        result_li =get_dnds_dist_dim_stats_from_seq(leaves+intnodes, win_size_perc=win_size_perc, dist_to_file=dist_to_file_li,
                                                    dim_only=dim_only, out_dist=out_dist, dim_range_from_data=dim_range_from_data)
        result.extend(result_li)

    else:
        if dist_to_file:
            dist_to_file_l=dist_to_file+'_leaves'
        else:
            dist_to_file_l=dist_to_file
        result =get_dnds_dist_dim_stats_from_seq(leaves, win_size_perc=win_size_perc, dist_to_file=dist_to_file_l,
                                                 dim_only=dim_only, out_dist=out_dist, dim_range_from_data=dim_range_from_data)

    if verbose:
        print('Results:', frac_allowed, result, flush=True)

    return(result)


def get_stats_from_simulated_tree(treefile, dim_only=True, verbose=True, include_internal=False, 
                                   dist_to_file=None, win_size_perc=0.3, out_dist=False, dim_out= None, 
                                   dim_stats_out=False, dim_range_from_data=False):
    
    """
    Function to calculate the dimensionality, average
    pairwise distance and dn/ds from a simulated tree in pickle file.

    Args:
        include_internal (bool): if False - dimensionality, distance and (optionally) dn/ds
            are only calculated for the leaves on the tree (extant proteins). The output is 
            then a tuple of 2 or 3 values ([dnds_evolved], distall_evolved, dim_evolved).
            If True - dimensionality, distance and (optionally) dn/ds are calculated for the 
            leaves only (first 2 or 3 values of the output), internal nodes only (second 2 or 3 
            values of the output) and for the mix of internal nodes and leaves (the last set of 
            values in the output tuple). Default: False.
        dist_to_file (None or str): name (suffix) of the file to write the pairwise distance 
            matrix, set to None to avoid recording the matrix (default).  
    
    """
    if type(treefile)==str: #input is a filename 
        with open(treefile, "rb") as f:
            tree = pickle.load(f)
        fn=os.path.basename(treefile)
    else: #input is an ete3.Tree instance
        tree=treefile
        fn=''
    leaves=[]
    if include_internal: #only include internal nodes if tree is not starlike
        intnodes=[]
        result=[]
        #get sequences from the tree
        for node in tree.traverse("levelorder"):
            if node.is_leaf():
                leaves.append(node.sequence)
            else:
                intnodes.append(node.sequence)
        #get dim and average dist of leaves only
        #set names for pdistm files
        if dist_to_file:
            dist_to_file_l=dist_to_file+'_leaves'
            dist_to_file_i=dist_to_file+'_anc'
            dist_to_file_li=dist_to_file+'_leaves_anc'
        else:
            dist_to_file_l=dist_to_file_i=dist_to_file_li=dist_to_file

        if dim_out:
            dim_out_name_l= dim_out+'_leaves'
            dim_out_name_i= dim_out+'_anc'
            dim_out_name_li=dim_out+'_leaves_anc'
        else:
            dim_out_name_i=dim_out_name_li=dim_out_name_l=dim_out

        result_l =get_dnds_dist_dim_stats_from_seq(leaves, win_size_perc=win_size_perc, dist_to_file=dist_to_file_l,
                                                   dim_only=dim_only, out_dist=out_dist, dim_out=dim_out_name_l, 
                                                   dim_stats_out=dim_stats_out, dim_range_from_data=dim_range_from_data)
        result.extend(result_l)
        #get dim and average dist of internal nodes only
        result_i =get_dnds_dist_dim_stats_from_seq(intnodes, win_size_perc=win_size_perc, dist_to_file=dist_to_file_i,
                                                   dim_only=dim_only, out_dist=out_dist, dim_out=dim_out_name_i, 
                                                   dim_stats_out=dim_stats_out, dim_range_from_data=dim_range_from_data)
        result.extend(result_i)
        #get dim and average dist of leaves with internal nodes 
        result_li =get_dnds_dist_dim_stats_from_seq(leaves+intnodes, win_size_perc=win_size_perc, dist_to_file=dist_to_file_li,
                                                    dim_only=dim_only, out_dist=out_dist, dim_out=dim_out_name_li, 
                                                    dim_stats_out=dim_stats_out, dim_range_from_data=dim_range_from_data)
        result.extend(result_li)

    else:
        #get sequences from the tree
        for node in tree.traverse("levelorder"):
            if node.is_leaf():
                leaves.append(node.sequence)
            else:
                continue
        if dist_to_file:
            dist_to_file_l=dist_to_file+'_leaves'
        else:
            dist_to_file_l=dist_to_file

        if dim_out:
            dim_out_name=dim_out+'_leaves'
        else:
            dim_out_name=dim_out

        result =get_dnds_dist_dim_stats_from_seq(leaves, win_size_perc=win_size_perc, dist_to_file=dist_to_file_l,
                                                 dim_only=dim_only, out_dist=out_dist, dim_out=dim_out_name, 
                                                 dim_stats_out=dim_stats_out, dim_range_from_data=dim_range_from_data)

    if verbose:
        print('Results:',fn, result, flush=True)

    return(result)


def get_ancestors_seqs_from_tree(tree, internal_to_fasta=False, outfolder=''):

    """
    Function to get ancestor sequences from a tree.
    Input:
    - tree in pickle format with node attributes "sequence"
    - internal_to_fasta - set to True to record ancestors and 
    ancestors+leaves in fasta files
    - outfolder - folder to write fasta files 
    Output:
    - tuple of lists with sequences:
    [leaves, ancestors, leaves+ancestors]
    """

    if '.pickle' in tree:
        #input is a file
        ogname='ali_'+re.findall('tree_(.+).pickle', os.path.basename(tree))[0]
        with open(tree, 'rb') as f:
            tree=pickle.load(f)
    else: #tree is a tree instance
        ogname='loaded_tree'
        pass

    intnodes=[]
    leaves=[]

    #get internal node and leaf sequences
    for node in tree.traverse("levelorder"):
        if node.is_leaf():
            leaves.append(node.sequence)
        else:
            intnodes.append(node.sequence)
    if internal_to_fasta:
        #record ancestors only 
        with open(outfolder+ogname+'_anc.fasta', 'w+') as af:
            af.write(''.join(['>'+str(ind)+'\n'+evseq+'\n' for ind, evseq in zip(range(len(leaves), len(leaves)+len(intnodes)), intnodes)]))

        #record ancestors and leaves in the same file
        with open(outfolder+ogname+'_leaves_anc.fasta', 'w+') as alf:
            alf.write(''.join(['>'+str(ind)+'\n'+evseq+'\n' for ind, evseq in enumerate(leaves+intnodes)]))

    return(leaves, intnodes, leaves+intnodes)


def dn_ds_from_tree(tree, return_all=True):

    """
    Funciton that calculates an average, median and variance of dn/ds 
    on one simulated phylogenetic tree. 
    Each tree node has to have such attributes: sequence, nonsyn_subs, syn_subs.
    """

    nonsyn_only_count=0
    leaves=tree.get_leaves()
    leaf_pairs=list(itertools.combinations(leaves, 2))
    dndslist=[]
    dndslist_float=[]
    for pair in leaf_pairs:
        anc=tree.get_common_ancestor(pair)
        nonsyn_subs=pair[0].nonsyn_subs+pair[1].nonsyn_subs-2*anc.nonsyn_subs
        syn_subs=pair[0].syn_subs+pair[1].syn_subs-2*anc.syn_subs
        syn_sites = dnds.syn_sum(pair[0].sequence, pair[1].sequence)
        non_sites = len(pair[0].sequence) - syn_sites
        pn = nonsyn_subs / non_sites
        ps = syn_subs / syn_sites
        try:
            dndslist.append(pn/ps)
            dndslist_float.append(float(pn/ps))
        except ZeroDivisionError:
                nonsyn_only_count=nonsyn_only_count+1

    if nonsyn_only_count!=0:
        print(nonsyn_only_count, 'dnds value ommited because of the present nonsyn subs, but no syn subs')
    if return_all:
        return(float(np.mean(dndslist)), float(np.median(dndslist)), float(np.var(dndslist)), dndslist_float)
    else:
        return(float(np.mean(dndslist)), float(np.median(dndslist)), float(np.var(dndslist)))


def count_independent_nonsyn_syn_subs_treelen(treefile):
    """
    Function that counts the total number 
    of independent substitutions ona a tree.

    Input: 
    - tree in pickle format with node attributes "nonsyn_subs"
    Output:
    - list: [filename, nonsyn_subs_count, syn_subs_count, total_treelength]

    All values are in the number of substitutions.
    To get the tree length in substitutuins per site, it needs to be 
    diveded by the length of the nucleotide sequence.
    """
    name=os.path.splitext(os.path.basename(treefile))[0]
    with open(treefile, "rb") as f:
        tree = pickle.load(f) 
    ns_unique=0
    s_unique=0
    for i in tree.traverse("levelorder"):
        if i.is_root():
            continue
        ns_unique=ns_unique+i.nonsyn_subs-i.up.nonsyn_subs
        s_unique=s_unique+i.syn_subs-i.up.syn_subs
    return([name, ns_unique, s_unique, s_unique+ns_unique])


def get_usage_aa_per_site(ntali, alphabet='nt', colfreqs_out=False):

    """
    Use only with simulated sequences that don't have gaps!
    """
    if type(ntali)==list: #input is a list of sequences as strings
        if alphabet=='nt':
            ali=MultipleSeqAlignment([SeqRecord(Seq(eaa)).translate() for eaa in ntali])
        else:
            ali=MultipleSeqAlignment([SeqRecord(Seq(eaa)) for eaa in ntali])
    else: #input is a fasta file 
        ntali=AlignIO.read(open(ntali), 'fasta')
        if alphabet=='nt':
            ali=MultipleSeqAlignment([eaa.translate() for eaa in ntali])
        else:
            ali=ntali
    colfreqs=[]
    #list of lists with all possible aa at each site 
    allaapersite=[]
    #get the length of sequences with gaps (alignment)
    length =  ali.get_alignment_length()
    #get the number of sequences in the alignment
    #count the number of sites with only one possible character
    n_invar_sites=0
    #get the alphabet size for every site (including gaps)
    col_alpha_size=[]
    #iterate over every column in the alignment and get mentionned values for every site
    for col in range(length):
        #get a column in the alignment as a string
        currcol=ali[:, col]
        colfreqs.append(np.unique(currcol, return_counts=True)[1])
        colvars=list(set(currcol))
        allaapersite.append(colvars)
        #get the number of characters in this column (excluding gaps)
        col_alpha_size.append(len(colvars))
        #if a column has the same character in all sequences count it as an invariant site
        if col_alpha_size[-1]==1:
            n_invar_sites=n_invar_sites+1
    if colfreqs_out:
        return(col_alpha_size, n_invar_sites, allaapersite, colfreqs)
    else:
        return(col_alpha_size, n_invar_sites, allaapersite)
    

def generate_sequences_from_allowed(list_allowed, weights=None, n_seq=1):
    """
    Function to generate random sequences from a list of allowed amino acids per site 
    produced by get_usage_aa_per_site (third element in the output).
    """

    sitelist=[]
    #iterating over sites
    if weights==None:
        for site in list_allowed:
            sitelist.append(random.choices(site, k=n_seq))
    else:
        for weight, site in zip(weights, list_allowed):
            sitelist.append(random.choices(site, weights=weight, k=n_seq))

    #transform list of sites to list of sequences
    seqlist=np.array(sitelist).T
    finalseqs=[]
    for sequence in seqlist:
        finalseqs.append(''.join(sequence))
    return(finalseqs)

# --- 5. Miscellaneous helper functions

def get_replicate_indices(nrep, nfs):
    """Function to get replicates indices for a range of simulations
    
    Inputs:
    - nrep: number of replicates per f (parameter value)
    - nfs: number of parameter values 

    Output:
    - list of indices, for example if nrep=3, nfs=4, we'll get:
    [0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2]
    """
    repcol=[]
    if type(nrep)==int:
        for i in range(nrep):
            repcol.extend([i]*nfs)
    else:
        for i in range(nrep[0], nrep[1]):   
            repcol.extend([i]*nfs)
    return(repcol)

def seq_w_id_to_file(seq_list, filename, idlist=None, exp_len=None):
    with open(filename, 'w') as f:  
        if idlist!=None:
            for seqid, seq in zip(idlist, seq_list):
                if exp_len:
                    if len(seq)==exp_len:
                        pass
                    else:
                        continue
                    f.write('>'+str(seqid)+'\n'+seq + '\n')
                else:
                    f.write('>'+str(ind)+'\n'+seq + '\n')   
        else:
            for ind, seq in enumerate(seq_list):
                if exp_len:
                    if len(seq)==exp_len:
                        pass
                    else:
                        continue
                    f.write('>'+str(ind)+'\n'+seq + '\n')
                else:
                    f.write('>'+str(ind)+'\n'+seq + '\n')                    